% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Method}\label{chapter:method}

As discussed in \autoref{chapter:introduction}, direct skeletonization of EM images is a under explored idea, more efforts are directed towards first segmenting the 3D volume and then skeletonizing it. But, it need not be done that way.

We propose a novel method for instance skeletonization of neuronal structures in EM images. The method presented here is motivated by existing Learning based skeletonization method for natural images, but the proposed method differs primarily in two  ways - First, it creates separate skeletons for each individual segment- we describe it as instance skeletonization. Second, it is for 3D images, which to the best of our knowledge has not been explored yet. 
 
\section{Encoding and Decoding Skeletons}
Previous skeletonization methods \textcolor{red}{cite old skeleton papers} do not take into account multiple objects in input images. Their prediction is a binary mask, marking only skeleton points as 'True', they are agnostic to the multiple objects.
But, in EM images, it is of outmost importance to separate skeletons of one object instance from another. It is not straight forward to construct a Deep Learning model which can directly demarcate skeleton for every object instance. Hence, a system of encoding must be devised to separate skeletons of multiple object instances in a postprocessing step and also to allow for a feasible loss metric for training. 

\cite{Wang2019} proposes 'DeepFlux' which encodes skeletons of objects in 2D images using a $\mathbb{R}^2$ vector field. It defines a 2D context region around skeleton, and all $\mathbb{R}^2$ vectors in that context region point to the nearest skeleton pixel. This provides a easy non mask based encoding to represent skeletons, and the objective of a Deep Net model would be to predict this field.

The proposed method is also inspired from this encoding, albeit for 3D skeletons and some other tweaks.

First, instead for creating a $\mathbb{R}^2$ field a $\mathbb{R}^3$ field for 3D skeletons is created. Ground Truth skeletons can either be manually generated by human annotators \textcolor{red}{cite KNOSSOS Tool}, or by using segmentation to skeletonization algorithms. The context region for a skeleton is also defined in $3D$ using a sphere of $N nm$ radius, and finally for all points in the context region a $\mathbb{R}^3$ field is defined such that the vectors point to the nearest skeleton voxel.
But the direction field is non-smooth if the skeletons are defined on a discrete grid. This is due to the fact that the direction vectors will jump abruptly from one skeleton point to another. Learning of a non-smooth field is not encouraged as Deep Nets are usually not apt to generate such fields. Hence, to create smoother versions of the field, first skeleton points are interpolated using splines and then a distance transform is calculated. Finally, the gradient of the distance transform defines a $\mathbb{R}^3$ encoding of the skeleton pixels. \textcolor{red}{create graphic of the flux and the context and directions}

To obtain the instance skeletons back from such an encoding, simple postprocessing tools can be used. First observation about the field is that, in a small neighborhood around the skeleton they point away from each other, while at other locations they are pointing almost in the same direction. This property can be used to identify skeleton voxels. The Divergence operator is apt for such field analysis. Divergence at diverging field location, which are skeleton points would be high, where as for all other location it would be low. Thresholding the divergence would allow to find the skeleton points. Finally for instance skeletonization, connected components analysis can be performed to separate skeleton instances.

The advantages for encoding and decoding the skeletons in such a manner are:
\begin{itemize}
	\item Deep Net model has to learn to look for both global and local properties while predicting the field. This helps to avoid local false merges due to small membrane breaks, as seen in boundary based methods.
	\item Voxel wise loss function for the deep net can be easily constructed. The loss metric is agnostic of skeleton instances.
	\item Decoding methods - Divergence and Connected Components analysis - are intuitive and fast, unlike watershed in case of boundary based methods.
	\item Learned field can be useful to solve false merges and splits in later post processing steps. 
\end{itemize}
